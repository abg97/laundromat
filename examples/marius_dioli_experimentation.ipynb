{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Matcher object from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nb_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"marius\"}, {\"LOWER\": \"dioli\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = \"Hei, mitt navn er Marius Dioli. Eg er nysgjerrig på kor mange poeng eg har.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_match(matcher, doc, id, matches):\n",
    "      print('Matched!', matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"MD matcher\", on_match, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched! [(10180913855843715433, 5, 7)]\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10180913855843715433 MD matcher 5 7 Marius Dioli\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg =  [{\"TEXT\": {\"REGEX\": r'(\\b\\d{11}\\b)|(\\b\\d{6}\\s\\d{5}\\b)'}}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=\"Mitt navn er robindra og mitt fødselsnummer er 15044216652\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checksum(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    span = doc[start:end]  # The matched span\n",
    "    fmt = \"%d%m%y\"\n",
    "    fnr = span[0].text\n",
    "    date = fnr[:6]\n",
    "    prsn = fnr[-5:]\n",
    "    try:\n",
    "        int(date)\n",
    "    except:\n",
    "        return\n",
    "    try:\n",
    "        dt.datetime.strptime(date, fmt)\n",
    "    except ValueError:\n",
    "        print(\"Invalid date\")\n",
    "    d1 = int(date[0])\n",
    "    d2 = int(date[1])\n",
    "\n",
    "    m1 = int(date[2])\n",
    "    m2 = int(date[3])\n",
    "\n",
    "    y1 = int(date[4])\n",
    "    y2 = int(date[5])\n",
    "\n",
    "    i1 = int(prsn[0])\n",
    "    i2 = int(prsn[1])\n",
    "    i3 = int(prsn[2])\n",
    "\n",
    "    k1 = int(prsn[3])\n",
    "    k2 = int(prsn[4])\n",
    "    k1_mod = (3 * d1 + 7 * d2 + 6 * m1 + m2 + 8 * y1 + 9 * y2 + 4 * i1 + 5 * i2 + 2 * i3) % 11\n",
    "    new_k1 = 0 if k1_mod == 0 else (11 - k1_mod)\n",
    "\n",
    "    if k1 != new_k1:\n",
    "        print(\"Invalid personnummer\")\n",
    "\n",
    "    k2_mod = (5 * d1 + 4 * d2 + 3 * m1 + 2 * m2 + 7 * y1 + 6 * y2 + 5 * i1 + 4 * i2 + 3 * i3 + 2 * k1) % 11\n",
    "    new_k2 = 0 if k2_mod == 0 else (11 - k2_mod)\n",
    "\n",
    "    if k2 != new_k2:\n",
    "        print(\"Invalid personnummer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737304374787103023 8 9 15044216652\n"
     ]
    }
   ],
   "source": [
    "matcher.add(\"fnr RegEx_med_checksum\", checksum, reg)\n",
    "doc = nlp(tx)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Entity Ruler object from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.nb import Norwegian\n",
    "from spacy.pipeline import EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = [{\"label\": \"FNR\", \"pattern\":[{\"TEXT\": {\"REGEX\": r'(\\b\\d{11}\\b)|(\\b\\d{6}\\s\\d{5}\\b)'}}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=\"Jeg er Robindra og mitt fødselsnummer er 15044216652\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nb_core_news_lg\")\n",
    "#nlp = Norwegian() is an empty model\n",
    "ruler = EntityRuler(nlp)\n",
    "ruler.add_patterns(reg)\n",
    "nlp.add_pipe(ruler)\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example text\n",
    "txt = \"Selv om det hører inn under sakprosaen, er det mange forfattere som skriver essayistisk; som altså vil si assosiativt og sirkulært i formen. Mange vil kalle essayet en blandingsgenre; Mia Bull Gundersen skriver for eksempel: «Essayet er en utpreget litterær blandingsform og befinner seg et sted mellom fiksjon og sakprosa» (1). En del tekster kan være essayistiske i formen, selv om de faller inn under andre genrebetegnelser. Dette gjelder både artikler, kronikker, petiter, kåserier og romaner. Essayet er en forholdsvis kort tekst, skrevet i førsteperson entall i en ikke-konkluderende form. Jo Bech-Karlsen (2) sier essayet skal være kunnskapsrikt, men ikke lærd i teoretisk vitenskapelig forstand. Ofte stiller essayet flere spørsmål enn det besvarer, og forfatteren av essayet henvender seg gjerne til sin likemann; en kunnskapsrik og opplyst leser. I motsetning til en artikkel, som er bygget opp med en innledning, drøfting og konklusjon, har essayet verken innledning eller avslutning. Leseren får ikke nødvendigvis svar på de spørsmålene teksten stiller, men skal likevel være klokere enn før han eller hun gikk i gang med lesningen. I likhet med essayet selv, omfatter essayets historie flere tradisjoner og avstikkere. De fleste betrakter Michel de Montaigne som essayets far. Montaigne (1533–1592) var en fransk adelsmann, politiker, filosof og forfatter som hadde stor innflytelse i sin samtid. Som trettiåring trakk han seg tilbake til familiens slott i Bordeaux, for i ensomhet å reflektere og skrive, i sitt tårn, omgitt av sine bøker. Begrepet essay er hentet fra tittelen på hans bøker: Les Essais I–III, som kom ut mellom 1780 og 1788. Det franske begrepet kan oversettes med forsøk, som peker tilbake på essayets åpne, prøvende og ikke-konkluderende form. Selv fortsatte Montaigne å redigere og endre på essayene sine resten av livet. Dette forsterker inntrykket av essayet som uferdig og åpent. Det er ofte store og evige spørsmål som drøftes i essayet, samtidig som ingenting synes å være for smått.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mia Bull Gundersen', 'PER', '33', '36'), ('Essayet', 'PER', '41', '42'), ('Essayet', 'PER', '92', '93'), ('Bech-Karlsen', 'ORG', '109', '110'), ('Michel de Montaigne', 'PER', '222', '225'), ('Montaigne', 'PER', '229', '230'), ('Bordeaux', 'LOC', '261', '262'), ('Montaigne', 'PER', '323', '324')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(txt)\n",
    "print([(ent.text, ent.label_, str(ent.start), str(ent.end)) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [(33, 36, 'PER'), (41, 42, 'PER'), (92, 93, 'PER'), (109, 110, 'ORG'), (222, 225, 'PER'), (229, 230, 'PER'), (261, 262, 'LOC'), (323, 324, 'PER')]\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0, (92, 93, 'PER'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0, (92, 93, 'PER'): 1.0, (109, 110, 'ORG'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0, (92, 93, 'PER'): 1.0, (109, 110, 'ORG'): 1.0, (222, 225, 'PER'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0, (92, 93, 'PER'): 1.0, (109, 110, 'ORG'): 1.0, (222, 225, 'PER'): 1.0, (229, 230, 'PER'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0, (92, 93, 'PER'): 1.0, (109, 110, 'ORG'): 1.0, (222, 225, 'PER'): 1.0, (229, 230, 'PER'): 1.0, (261, 262, 'LOC'): 1.0})\n",
      "entity_scores defaultdict(<class 'float'>, {(33, 36, 'PER'): 1.0, (41, 42, 'PER'): 1.0, (92, 93, 'PER'): 1.0, (109, 110, 'ORG'): 1.0, (222, 225, 'PER'): 1.0, (229, 230, 'PER'): 1.0, (261, 262, 'LOC'): 1.0, (323, 324, 'PER'): 1.0})\n"
     ]
    }
   ],
   "source": [
    "beams = nlp.entity.beam_parse([doc], beam_width=16, beam_density=0.0001)\n",
    "for score, ents in nlp.entity.moves.get_beam_parses(beams[0]):\n",
    "    print (score, ents)\n",
    "    entity_scores = defaultdict(float)\n",
    "    for start, end, label in ents:\n",
    "        # print (\"here\")\n",
    "        entity_scores[(start, end, label)] += score\n",
    "        print ('entity_scores', entity_scores)\n",
    "\n",
    "for (start, end, label),value in entity_scores.items():\n",
    "        if label == 'LOCATION':\n",
    "            print (start, tokens[start], value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing custom package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nav_pii_anon.spacy.spacy_model import SpacyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = SpacyModel(spacy.load(\"nb_core_news_lg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Robindra', 'PER', 2, 3)]\n"
     ]
    }
   ],
   "source": [
    "nlp.predict(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Robindra', 'PER', 2, 3), ('15044216652', 'FNR', 7, 8)]\n"
     ]
    }
   ],
   "source": [
    "nlp.predict(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
